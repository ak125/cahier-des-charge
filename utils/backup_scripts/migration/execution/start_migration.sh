#!/bin/bash
#
# Pipeline de migration automatique MySQL ‚Üí PostgreSQL ‚Üí Prisma ‚Üí Supabase
# Ce script orchestre le processus complet de migration
#

set -e  # Arr√™ter l'ex√©cution si une commande √©choue

# Charger les variables d'environnement
if [ -f .env ]; then
  source .env
else
  echo "‚ùå Fichier .env manquant. Veuillez cr√©er un fichier .env avec les variables n√©cessaires."
  exit 1
fi

# Configuration
WORKSPACE_DIR=$(pwd)
TIMESTAMP=$(date +"%Y%m%d-%H%M%S")
LOGS_DIR="${WORKSPACE_DIR}/logs/migration-${TIMESTAMP}"
REPORTS_DIR="${WORKSPACE_DIR}/reports/migration-${TIMESTAMP}"
CONFIG_FILE="${WORKSPACE_DIR}/config/migration/migration-config.json"
MYSQL_DUMP_FILE="${REPORTS_DIR}/dump.mysql.sql"
PG_DUMP_FILE="${REPORTS_DIR}/dump.pg.sql"
SCHEMA_PRISMA_FILE="${REPORTS_DIR}/schema.prisma"
SUPABASE_SCHEMA_FILE="${REPORTS_DIR}/supabase.sql"
AUDIT_REPORT="${REPORTS_DIR}/migration_audit.json"
SUMMARY_FILE="${REPORTS_DIR}/migration_summary.md"

# Cr√©ation des r√©pertoires de logs et rapports
mkdir -p "${LOGS_DIR}"
mkdir -p "${REPORTS_DIR}"

# Fonction pour enregistrer les logs
log() {
  local level=$1
  local message=$2
  local timestamp=$(date +"%Y-%m-%d %H:%M:%S")
  echo "[$timestamp] [$level] $message" | tee -a "${LOGS_DIR}/migration.log"
}

# Fonction pour ex√©cuter une commande avec logging
run_command() {
  local command=$1
  local description=$2
  local log_file="${LOGS_DIR}/${3:-command.log}"
  
  log "INFO" "‚è≥ $description"
  echo "$ $command" > "$log_file"
  
  if eval "$command" >> "$log_file" 2>&1; then
    log "SUCCESS" "‚úÖ $description - R√©ussi"
    return 0
  else
    log "ERROR" "‚ùå $description - √âchec (voir $log_file)"
    exit 1
  fi
}

# V√©rification des pr√©requis
check_prerequisites() {
  log "INFO" "üîç V√©rification des pr√©requis..."
  
  # V√©rifier si les commandes n√©cessaires sont install√©es
  for cmd in mysqldump node npm npx ts-node prisma supabase jq; do
    if ! command -v $cmd &> /dev/null; then
      log "ERROR" "‚ùå $cmd n'est pas install√©. Veuillez l'installer."
      exit 1
    fi
  done
  
  # V√©rifier la pr√©sence des fichiers de configuration
  if [ ! -f "$CONFIG_FILE" ]; then
    log "ERROR" "‚ùå Fichier de configuration manquant: $CONFIG_FILE"
    exit 1
  fi
  
  log "SUCCESS" "‚úÖ Tous les pr√©requis sont satisfaits."
}

# Phase 1: Extraction MySQL
extract_mysql() {
  log "INFO" "üîÑ Phase 1: Extraction MySQL"
  
  # R√©cup√©rer les variables de configuration
  MYSQL_HOST=$(jq -r '.mysql.host' "$CONFIG_FILE")
  MYSQL_PORT=$(jq -r '.mysql.port' "$CONFIG_FILE")
  MYSQL_USER=$(jq -r '.mysql.user' "$CONFIG_FILE")
  MYSQL_PASSWORD=$(jq -r '.mysql.password' "$CONFIG_FILE")
  MYSQL_DATABASE=$(jq -r '.mysql.database' "$CONFIG_FILE")
  
  # Dump de la base MySQL
  run_command "mysqldump -h ${MYSQL_HOST} -P ${MYSQL_PORT} -u ${MYSQL_USER} -p${MYSQL_PASSWORD} \
    --routines --triggers --no-tablespaces \
    --column-statistics=0 --set-gtid-purged=OFF \
    ${MYSQL_DATABASE} > ${MYSQL_DUMP_FILE}" \
    "Extraction du sch√©ma et des donn√©es MySQL" "mysql_dump.log"
  
  # Analyse du sch√©ma MySQL avec l'agent mysql-analyzer
  run_command "cd ${WORKSPACE_DIR} && ts-node packages/mcp-agents/mysql-analyzer.ts \
    --input=${MYSQL_DUMP_FILE} \
    --output=${REPORTS_DIR}/mysql_analysis.json" \
    "Analyse du sch√©ma MySQL" "mysql_analyzer.log"
  
  log "SUCCESS" "‚úÖ Phase 1 termin√©e: Extraction MySQL"
}

# Phase 2: Mapping MySQL ‚Üí PostgreSQL
map_to_postgresql() {
  log "INFO" "üîÑ Phase 2: Mapping MySQL ‚Üí PostgreSQL"
  
  # Option 1: Utiliser pgloader (si disponible)
  if command -v pgloader &> /dev/null; then
    # G√©n√©rer un fichier de configuration pgloader
    cat > "${REPORTS_DIR}/pgloader.conf" <<EOL
LOAD DATABASE
     FROM mysql://${MYSQL_USER}:${MYSQL_PASSWORD}@${MYSQL_HOST}:${MYSQL_PORT}/${MYSQL_DATABASE}
     INTO postgresql://${PG_USER}:${PG_PASSWORD}@${PG_HOST}:${PG_PORT}/${PG_DATABASE}
 WITH include no drop,
      create tables,
      create indexes,
      preserve index names,
      reset sequences,
      foreign keys,
      disable triggers,
      truncate
 CAST
      type int with extra auto_increment to serial,
      type tinyint when (= 1) to boolean using tinyint-to-boolean,
      type varchar to text,
      type datetime to timestamp
EOL

    run_command "pgloader ${REPORTS_DIR}/pgloader.conf" \
      "Conversion de MySQL √† PostgreSQL avec pgloader" "pgloader.log"
  
  # Option 2: Utiliser notre propre agent de mapping
  else
    log "INFO" "pgloader non trouv√©, utilisation de notre agent mysql-to-postgresql"
    
    # R√©cup√©rer les variables de configuration PostgreSQL
    PG_HOST=$(jq -r '.postgresql.host' "$CONFIG_FILE")
    PG_PORT=$(jq -r '.postgresql.port' "$CONFIG_FILE")
    PG_USER=$(jq -r '.postgresql.user' "$CONFIG_FILE")
    PG_PASSWORD=$(jq -r '.postgresql.password' "$CONFIG_FILE")
    PG_DATABASE=$(jq -r '.postgresql.database' "$CONFIG_FILE")
    
    run_command "cd ${WORKSPACE_DIR} && ts-node packages/mcp-agents/mysql-to-postgresql.ts \
      --input=${MYSQL_DUMP_FILE} \
      --output=${PG_DUMP_FILE} \
      --map=${REPORTS_DIR}/type_mapping.json" \
      "Conversion de MySQL √† PostgreSQL avec agent personnalis√©" "mysql_to_pg.log"
      
    # Ex√©cuter le script PostgreSQL g√©n√©r√©
    run_command "PGPASSWORD=${PG_PASSWORD} psql -h ${PG_HOST} -p ${PG_PORT} -U ${PG_USER} -d ${PG_DATABASE} -f ${PG_DUMP_FILE}" \
      "Import du sch√©ma et des donn√©es dans PostgreSQL" "pg_import.log"
  fi
  
  # G√©n√©ration d'un rapport de diff√©rences
  run_command "cd ${WORKSPACE_DIR} && ts-node packages/mcp-agents/schema-diff.ts \
    --mysql=${REPORTS_DIR}/mysql_analysis.json \
    --pg=${PG_DUMP_FILE} \
    --output=${REPORTS_DIR}/schema_diff.json" \
    "G√©n√©ration du rapport de diff√©rences entre MySQL et PostgreSQL" "schema_diff.log"
  
  log "SUCCESS" "‚úÖ Phase 2 termin√©e: Mapping MySQL ‚Üí PostgreSQL"
}

# Phase 3: G√©n√©ration Prisma
generate_prisma() {
  log "INFO" "üîÑ Phase 3: G√©n√©ration du sch√©ma Prisma"
  
  # Initialisation de Prisma s'il n'est pas d√©j√† pr√©sent
  if [ ! -f "${WORKSPACE_DIR}/prisma/schema.prisma" ]; then
    run_command "cd ${WORKSPACE_DIR} && npx prisma init" \
      "Initialisation de Prisma" "prisma_init.log"
  fi
  
  # R√©cup√©ration du sch√©ma depuis PostgreSQL
  DATABASE_URL="postgresql://${PG_USER}:${PG_PASSWORD}@${PG_HOST}:${PG_PORT}/${PG_DATABASE}"
  
  run_command "cd ${WORKSPACE_DIR} && DATABASE_URL=\"${DATABASE_URL}\" npx prisma db pull --force" \
    "R√©cup√©ration du sch√©ma depuis PostgreSQL" "prisma_db_pull.log"
  
  # Copier le schema.prisma g√©n√©r√©
  cp "${WORKSPACE_DIR}/prisma/schema.prisma" "${SCHEMA_PRISMA_FILE}"
  
  # Nettoyage et optimisation du sch√©ma Prisma
  run_command "cd ${WORKSPACE_DIR} && ts-node packages/mcp-agents/prisma-optimizer.ts \
    --input=${SCHEMA_PRISMA_FILE} \
    --output=${SCHEMA_PRISMA_FILE}" \
    "Optimisation du sch√©ma Prisma" "prisma_optimizer.log"
  
  # Validation du sch√©ma Prisma
  run_command "cd ${WORKSPACE_DIR} && DATABASE_URL=\"${DATABASE_URL}\" npx prisma validate" \
    "Validation du sch√©ma Prisma" "prisma_validate.log"
  
  log "SUCCESS" "‚úÖ Phase 3 termin√©e: G√©n√©ration du sch√©ma Prisma"
}

# Phase 4: D√©ploiement Supabase
deploy_supabase() {
  log "INFO" "üîÑ Phase 4: D√©ploiement Supabase"
  
  # R√©cup√©rer les variables de configuration Supabase
  SUPABASE_PROJECT_ID=$(jq -r '.supabase.project_id' "$CONFIG_FILE")
  SUPABASE_DB_PASSWORD=$(jq -r '.supabase.db_password' "$CONFIG_FILE")
  
  # Connexion √† Supabase
  run_command "supabase login" \
    "Connexion √† Supabase" "supabase_login.log"
    
  # Linkage au projet Supabase
  run_command "supabase link --project-ref ${SUPABASE_PROJECT_ID}" \
    "Liaison au projet Supabase" "supabase_link.log"
  
  # G√©n√©rer un script de migration pour Supabase
  DATABASE_URL_SOURCE="postgresql://${PG_USER}:${PG_PASSWORD}@${PG_HOST}:${PG_PORT}/${PG_DATABASE}"
  DATABASE_URL_TARGET="postgresql://postgres:${SUPABASE_DB_PASSWORD}@db.${SUPABASE_PROJECT_ID}.supabase.co:5432/postgres"
  
  run_command "cd ${WORKSPACE_DIR} && npx prisma migrate diff \
    --from-url=\"${DATABASE_URL_SOURCE}\" \
    --to-url=\"${DATABASE_URL_TARGET}\" \
    --script > ${SUPABASE_SCHEMA_FILE}" \
    "G√©n√©ration du script de migration Supabase" "supabase_migrate_diff.log"
  
  # Ex√©cuter le script de migration dans Supabase
  run_command "supabase db execute --file ${SUPABASE_SCHEMA_FILE}" \
    "Ex√©cution du script de migration dans Supabase" "supabase_deploy.log"
    
  # V√©rifier les tables dans Supabase
  run_command "supabase db tables" \
    "V√©rification des tables dans Supabase" "supabase_tables.log"
  
  log "SUCCESS" "‚úÖ Phase 4 termin√©e: D√©ploiement Supabase"
}

# Phase 5: Int√©gration MCP
integrate_mcp() {
  log "INFO" "üîÑ Phase 5: Int√©gration MCP"
  
  # R√©cup√©rer les variables de configuration n8n
  N8N_WEBHOOK_URL=$(jq -r '.n8n.webhook_url' "$CONFIG_FILE")
  
  # G√©n√©ration des mappings pour les agents MCP
  run_command "cd ${WORKSPACE_DIR} && ts-node packages/mcp-agents/generate-mappings.ts \
    --mysql=${REPORTS_DIR}/mysql_analysis.json \
    --pg=${REPORTS_DIR}/schema_diff.json \
    --prisma=${SCHEMA_PRISMA_FILE} \
    --output=${REPORTS_DIR}/mcp_mappings.json" \
    "G√©n√©ration des mappings pour les agents MCP" "mcp_mappings.log"
  
  # Notification du webhook n8n pour lancer les workflows
  run_command "curl -s -X POST ${N8N_WEBHOOK_URL} \
    -H 'Content-Type: application/json' \
    -d '{\"event\": \"migration_completed\", \"timestamp\": \"$(date -u +\"%Y-%m-%dT%H:%M:%SZ\")\", \"mappingFile\": \"${REPORTS_DIR}/mcp_mappings.json\"}'" \
    "Notification du webhook n8n" "n8n_webhook.log"
  
  log "SUCCESS" "‚úÖ Phase 5 termin√©e: Int√©gration MCP"
}

# Phase 6: Validation
validate_migration() {
  log "INFO" "üîÑ Phase 6: Validation de la migration"
  
  # Ex√©cuter des tests de validation
  run_command "cd ${WORKSPACE_DIR} && ts-node packages/mcp-agents/migration-validator.ts \
    --mappings=${REPORTS_DIR}/mcp_mappings.json \
    --mysql=${REPORTS_DIR}/mysql_analysis.json \
    --pg=${REPORTS_DIR}/schema_diff.json \
    --prisma=${SCHEMA_PRISMA_FILE} \
    --output=${AUDIT_REPORT}" \
    "Validation de la migration" "migration_validator.log"
  
  # G√©n√©rer un rapport de synth√®se
  run_command "cd ${WORKSPACE_DIR} && ts-node scripts/generate-summary.ts \
    --audit=${AUDIT_REPORT} \
    --output=${SUMMARY_FILE}" \
    "G√©n√©ration du rapport de synth√®se" "summary_generator.log"
  
  # Afficher le r√©sum√© de la migration
  log "INFO" "üìã R√©sum√© de la migration :"
  cat "${SUMMARY_FILE}"
  
  log "SUCCESS" "‚úÖ Phase 6 termin√©e: Validation de la migration"
}

# Fonction principale
main() {
  log "INFO" "üöÄ D√©marrage du pipeline de migration MySQL ‚Üí PostgreSQL ‚Üí Prisma ‚Üí Supabase"
  
  # V√©rifier les pr√©requis
  check_prerequisites
  
  # Ex√©cuter les phases du pipeline
  extract_mysql
  map_to_postgresql
  generate_prisma
  deploy_supabase
  integrate_mcp
  validate_migration
  
  log "SUCCESS" "üéâ Pipeline de migration termin√© avec succ√®s! Rapports disponibles dans ${REPORTS_DIR}"
  echo "R√©sum√© de la migration : ${SUMMARY_FILE}"
}

# Ex√©cuter la fonction principale
main