#!/bin/bash
#
# Script d'automatisation complÃ¨te pour migrer MySQL â†’ Supabase (PostgreSQL)
# Utilise Navicat + scripts complÃ©mentaires + agents IA (MCP + n8n)
#

set -e  # ArrÃªte l'exÃ©cution en cas d'erreur

# Couleurs pour les messages
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
RED='\033[0;31m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Configuration
WORKSPACE_DIR=$(pwd)
TIMESTAMP=$(date +"%Y%m%d-%H%M%S")
CONFIG_FILE="${WORKSPACE_DIR}/migration-config.json"
LOGS_DIR="${WORKSPACE_DIR}/logs/migration-${TIMESTAMP}"
REPORTS_DIR="${WORKSPACE_DIR}/reports/migration-${TIMESTAMP}"
EXPORTS_DIR="${WORKSPACE_DIR}/exports/${TIMESTAMP}"
SCHEMA_MAP_FILE="${REPORTS_DIR}/schema_map.json"
N8N_WORKFLOW_FILE="${WORKSPACE_DIR}/config/migration/migration_pipeline.n8n.json"
DATA_REPORT_FILE="${REPORTS_DIR}/migration_report.json"

# Options de ligne de commande
VERBOSE=false
SKIP_NAVICAT=false
SKIP_EXPORT=false
SKIP_UPLOAD=false
SKIP_VERIFICATION=false
EXPORT_FORMAT="csv"  # ou "sql"
TABLES=""
USE_N8N=true

# Fonction d'aide
print_usage() {
  echo "Usage: $0 [options]"
  echo "Options:"
  echo "  --config=FILE         Fichier de configuration (migration-config.json par dÃ©faut)"
  echo "  --skip-navicat        Ignorer l'Ã©tape d'export Navicat (utilise uniquement les scripts)"
  echo "  --skip-export         Ignorer l'Ã©tape d'export (utilise des fichiers existants)"
  echo "  --skip-upload         Ignorer l'Ã©tape d'upload vers Supabase"
  echo "  --skip-verification   Ignorer l'Ã©tape de vÃ©rification"
  echo "  --export-format=TYPE  Format d'export (csv ou sql, csv par dÃ©faut)"
  echo "  --tables=LIST         Liste de tables Ã  migrer (toutes par dÃ©faut)"
  echo "  --disable-n8n         Ne pas utiliser n8n pour l'orchestration"
  echo "  --verbose             Afficher plus d'informations"
  echo "  --help                Afficher cette aide"
}

# Traitement des options
for i in "$@"; do
  case $i in
    --config=*)
      CONFIG_FILE="${i#*=}"
      shift
      ;;
    --skip-navicat)
      SKIP_NAVICAT=true
      shift
      ;;
    --skip-export)
      SKIP_EXPORT=true
      shift
      ;;
    --skip-upload)
      SKIP_UPLOAD=true
      shift
      ;;
    --skip-verification)
      SKIP_VERIFICATION=true
      shift
      ;;
    --export-format=*)
      EXPORT_FORMAT="${i#*=}"
      shift
      ;;
    --tables=*)
      TABLES="${i#*=}"
      shift
      ;;
    --disable-n8n)
      USE_N8N=false
      shift
      ;;
    --verbose)
      VERBOSE=true
      shift
      ;;
    --help)
      print_usage
      exit 0
      ;;
    *)
      # Option inconnue
      echo "Option inconnue: $i"
      print_usage
      exit 1
      ;;
  esac
done

# CrÃ©ation des rÃ©pertoires
mkdir -p "${LOGS_DIR}"
mkdir -p "${REPORTS_DIR}"
mkdir -p "${EXPORTS_DIR}"

# Fonction pour les logs
log() {
  local level="$1"
  local message="$2"
  local log_file="${LOGS_DIR}/migration.log"
  local timestamp=$(date +"%Y-%m-%d %H:%M:%S")
  
  case $level in
    "INFO")
      echo -e "[$timestamp] [${BLUE}INFO${NC}] $message" | tee -a "$log_file"
      ;;
    "SUCCESS")
      echo -e "[$timestamp] [${GREEN}SUCCESS${NC}] $message" | tee -a "$log_file"
      ;;
    "WARNING")
      echo -e "[$timestamp] [${YELLOW}WARNING${NC}] $message" | tee -a "$log_file"
      ;;
    "ERROR")
      echo -e "[$timestamp] [${RED}ERROR${NC}] $message" | tee -a "$log_file"
      ;;
    *)
      echo -e "[$timestamp] [$level] $message" | tee -a "$log_file"
      ;;
  esac
}

# Fonction pour exÃ©cuter des commandes et logger le rÃ©sultat
run_command() {
  local command="$1"
  local description="$2"
  local log_file="${LOGS_DIR}/${3:-command.log}"
  
  log "INFO" "â³ $description"
  
  if eval "$command" >> "$log_file" 2>&1; then
    log "SUCCESS" "âœ… $description"
    return 0
  else
    log "ERROR" "âŒ $description a Ã©chouÃ©. Voir le fichier log: $log_file"
    if [ "$4" != "continue" ]; then
      exit 1
    fi
    return 1
  fi
}

# VÃ©rification des prÃ©requis
check_prerequisites() {
  log "INFO" "ðŸ” VÃ©rification des prÃ©requis..."
  
  # VÃ©rifier si le fichier de configuration existe
  if [ ! -f "$CONFIG_FILE" ]; then
    log "ERROR" "Le fichier de configuration n'existe pas: $CONFIG_FILE"
    exit 1
  fi
  
  # VÃ©rifier les outils requis
  if [ "$SKIP_NAVICAT" = false ]; then
    # Pour Navicat, on ne peut pas vraiment vÃ©rifier automatiquement, donc on demande confirmation
    echo -e "${YELLOW}âš ï¸  Ce script va tenter d'utiliser Navicat. Assurez-vous que Navicat est installÃ© et configurÃ©.${NC}"
    echo "Appuyez sur EntrÃ©e pour continuer, ou Ctrl+C pour annuler."
    read -r
  fi
  
  # VÃ©rifier node, npm, ts-node, etc.
  for cmd in node npm npx ts-node jq; do
    if ! command -v $cmd &> /dev/null; then
      log "ERROR" "Commande requise non trouvÃ©e: $cmd"
      exit 1
    fi
  fi
  
  # VÃ©rifier n8n si utilisÃ©
  if [ "$USE_N8N" = true ]; then
    if ! command -v n8n &> /dev/null; then
      log "WARNING" "n8n n'est pas installÃ©. Installation en cours..."
      run_command "npm install -g n8n" "Installation de n8n"
    fi
  fi
  
  log "SUCCESS" "âœ… Tous les prÃ©requis sont satisfaits"
}

# Charger les configurations depuis le fichier JSON
load_config() {
  if command -v jq &> /dev/null; then
    echo $(jq -r "$1" "$CONFIG_FILE" 2>/dev/null || echo "$2")
  else
    log "WARNING" "jq n'est pas installÃ©, utilisation des valeurs par dÃ©faut"
    echo "$2"
  fi
}

# Phase 1: Extraction et mapping MySQL â†’ PostgreSQL
extract_and_map() {
  log "INFO" "ðŸ”„ Phase 1: Extraction et mapping MySQL â†’ PostgreSQL"
  
  # RÃ©cupÃ©rer les informations de connexion MySQL depuis le fichier de configuration
  MYSQL_HOST=$(load_config '.mysql.host' "localhost")
  MYSQL_PORT=$(load_config '.mysql.port' "3306")
  MYSQL_USER=$(load_config '.mysql.user' "root")
  MYSQL_PASSWORD=$(load_config '.mysql.password' "")
  MYSQL_DATABASE=$(load_config '.mysql.database' "")
  
  # Si les tables ne sont pas spÃ©cifiÃ©es, rÃ©cupÃ©rer toutes les tables
  if [ -z "$TABLES" ]; then
    log "INFO" "RÃ©cupÃ©ration de la liste des tables MySQL..."
    TABLES=$(mysql -h "$MYSQL_HOST" -P "$MYSQL_PORT" -u "$MYSQL_USER" -p"$MYSQL_PASSWORD" -N -e "SHOW TABLES FROM $MYSQL_DATABASE;" | tr '\n' ' ')
    if [ -z "$TABLES" ]; then
      log "ERROR" "Aucune table trouvÃ©e dans la base de donnÃ©es MySQL"
      exit 1
    fi
    log "INFO" "Tables dÃ©tectÃ©es: $TABLES"
  fi
  
  # GÃ©nÃ©rer le mapping des types MySQL â†’ PostgreSQL avec l'agent MCP
  log "INFO" "GÃ©nÃ©ration du mapping des types MySQL â†’ PostgreSQL..."
  run_command "cd ${WORKSPACE_DIR} && npx ts-node agents/migration/mysql-to-pg.ts \
    --host=${MYSQL_HOST} \
    --port=${MYSQL_PORT} \
    --user=${MYSQL_USER} \
    --password=${MYSQL_PASSWORD} \
    --database=${MYSQL_DATABASE} \
    --output=${SCHEMA_MAP_FILE}" \
    "GÃ©nÃ©ration du mapping des types" "mysql_to_pg.log"
  
  log "SUCCESS" "âœ… Phase 1 terminÃ©e: Extraction et mapping"
}

# Phase 2: Export des donnÃ©es (Navicat ou script)
export_data() {
  log "INFO" "ðŸ”„ Phase 2: Export des donnÃ©es"
  
  if [ "$SKIP_EXPORT" = true ]; then
    log "WARNING" "Export ignorÃ© (--skip-export)"
    return 0
  fi
  
  # Navicat (utilisation manuelle guidÃ©e)
  if [ "$SKIP_NAVICAT" = false ]; then
    echo -e "${YELLOW}âš ï¸  Ã‰tape manuelle requise: Export Navicat${NC}"
    echo "1. Ouvrez Navicat et connectez-vous Ã  votre base de donnÃ©es MySQL"
    echo "2. SÃ©lectionnez les tables: $TABLES"
    echo "3. Clic droit > Export Wizard > choisissez $EXPORT_FORMAT"
    echo "4. Enregistrez les fichiers dans: $EXPORTS_DIR"
    echo "5. Appuyez sur EntrÃ©e une fois l'export terminÃ©"
    read -r
    
    # VÃ©rifier que les fichiers ont bien Ã©tÃ© exportÃ©s
    for table in $TABLES; do
      if [ ! -f "$EXPORTS_DIR/$table.$EXPORT_FORMAT" ]; then
        log "WARNING" "Fichier attendu non trouvÃ©: $EXPORTS_DIR/$table.$EXPORT_FORMAT"
      else
        log "SUCCESS" "âœ… Fichier trouvÃ©: $table.$EXPORT_FORMAT"
      fi
    done
  else
    # Export via script automatique
    log "INFO" "Export automatique via script..."
    
    if [ "$EXPORT_FORMAT" = "csv" ]; then
      run_command "cd ${WORKSPACE_DIR} && npx ts-node tools/export-csv.ts \
        --config=${CONFIG_FILE} \
        --output=${EXPORTS_DIR} \
        --tables=\"${TABLES}\"" \
        "Export CSV des tables" "export_csv.log"
    else
      # Export SQL
      for table in $TABLES; do
        run_command "mysqldump -h ${MYSQL_HOST} -P ${MYSQL_PORT} -u ${MYSQL_USER} -p${MYSQL_PASSWORD} \
          ${MYSQL_DATABASE} ${table} > ${EXPORTS_DIR}/${table}.sql" \
          "Export SQL de la table $table" "export_sql_${table}.log" "continue"
      done
    fi
  fi
  
  log "SUCCESS" "âœ… Phase 2 terminÃ©e: Export des donnÃ©es"
}

# Phase 3: Upload et import dans Supabase
upload_to_supabase() {
  log "INFO" "ðŸ”„ Phase 3: Upload vers Supabase"
  
  if [ "$SKIP_UPLOAD" = true ]; then
    log "WARNING" "Upload ignorÃ© (--skip-upload)"
    return 0
  fi
  
  # RÃ©cupÃ©rer les informations de connexion Supabase
  SUPABASE_URL=$(load_config '.supabase.url' "")
  SUPABASE_KEY=$(load_config '.supabase.key' "")
  SUPABASE_DB_HOST=$(load_config '.supabase.db_host' "")
  SUPABASE_DB_PORT=$(load_config '.supabase.db_port' "5432")
  SUPABASE_DB_USER=$(load_config '.supabase.db_user' "postgres")
  SUPABASE_DB_PASSWORD=$(load_config '.supabase.db_password' "")
  SUPABASE_DB_NAME=$(load_config '.supabase.db_name' "postgres")
  
  if [ -z "$SUPABASE_URL" ] || [ -z "$SUPABASE_KEY" ]; then
    log "ERROR" "Informations de connexion Supabase manquantes"
    exit 1
  fi
  
  # Choix de la mÃ©thode d'upload
  if [ "$USE_N8N" = true ] && [ -f "$N8N_WORKFLOW_FILE" ]; then
    # MÃ©thode n8n
    log "INFO" "Upload via n8n workflow..."
    
    # Mettre Ã  jour le workflow n8n avec les chemins des fichiers exportÃ©s
    TMP_WORKFLOW=$(mktemp)
    jq --arg dir "$EXPORTS_DIR" '.nodes[] | select(.type == "n8n-nodes-base.readBinaryFiles") | .parameters.path = $dir' "$N8N_WORKFLOW_FILE" > "$TMP_WORKFLOW"
    mv "$TMP_WORKFLOW" "${REPORTS_DIR}/updated_workflow.json"
    
    # ExÃ©cuter le workflow n8n
    run_command "n8n execute --workflow ${REPORTS_DIR}/updated_workflow.json" \
      "ExÃ©cution du workflow n8n pour l'upload" "n8n_execute.log"
  else
    # MÃ©thode script TS
    log "INFO" "Upload via script Prisma/TS..."
    
    if [ "$EXPORT_FORMAT" = "csv" ]; then
      run_command "cd ${WORKSPACE_DIR} && npx ts-node tools/import-csv-to-supabase.ts \
        --config=${CONFIG_FILE} \
        --input=${EXPORTS_DIR} \
        --schema-map=${SCHEMA_MAP_FILE}" \
        "Import CSV vers Supabase" "import_csv_supabase.log"
    else
      # Import SQL
      # On utilise psql pour l'import SQL
      for table in $TABLES; do
        # On modifie d'abord le SQL pour adapter Ã  PostgreSQL avec notre agent
        run_command "cd ${WORKSPACE_DIR} && npx ts-node tools/convert-mysql-sql-to-pg.ts \
          --input=${EXPORTS_DIR}/${table}.sql \
          --output=${EXPORTS_DIR}/${table}.pg.sql \
          --schema-map=${SCHEMA_MAP_FILE}" \
          "Conversion SQL MySQL â†’ PostgreSQL pour $table" "convert_sql_${table}.log" "continue"
        
        # Puis on importe dans Supabase
        run_command "PGPASSWORD=${SUPABASE_DB_PASSWORD} psql -h ${SUPABASE_DB_HOST} -p ${SUPABASE_DB_PORT} -U ${SUPABASE_DB_USER} -d ${SUPABASE_DB_NAME} -f ${EXPORTS_DIR}/${table}.pg.sql" \
          "Import SQL dans Supabase pour $table" "import_sql_${table}.log" "continue"
      done
    fi
  fi
  
  log "SUCCESS" "âœ… Phase 3 terminÃ©e: Upload vers Supabase"
}

# Phase 4: VÃ©rification des donnÃ©es
verify_data() {
  log "INFO" "ðŸ”„ Phase 4: VÃ©rification des donnÃ©es"
  
  if [ "$SKIP_VERIFICATION" = true ]; then
    log "WARNING" "VÃ©rification ignorÃ©e (--skip-verification)"
    return 0
  fi
  
  # ExÃ©cuter l'agent de vÃ©rification
  run_command "cd ${WORKSPACE_DIR} && npx ts-node agents/migration/data-verifier.ts \
    --config=${CONFIG_FILE} \
    --tables=\"${TABLES}\" \
    --output=${DATA_REPORT_FILE}" \
    "VÃ©rification des donnÃ©es" "data_verify.log"
  
  # VÃ©rifier si des problÃ¨mes ont Ã©tÃ© dÃ©tectÃ©s
  if jq -e '.problems | length > 0' "$DATA_REPORT_FILE" > /dev/null; then
    log "WARNING" "âš ï¸ Des problÃ¨mes ont Ã©tÃ© dÃ©tectÃ©s durant la vÃ©rification. Voir: $DATA_REPORT_FILE"
  else
    log "SUCCESS" "âœ… Aucun problÃ¨me dÃ©tectÃ© durant la vÃ©rification"
  fi
  
  log "SUCCESS" "âœ… Phase 4 terminÃ©e: VÃ©rification des donnÃ©es"
}

# Phase 5: Orchestration finale et webhook
finalize() {
  log "INFO" "ðŸ”„ Phase 5: Finalisation et orchestration"
  
  # GÃ©nÃ©rer un rÃ©sumÃ© de la migration
  log "INFO" "GÃ©nÃ©ration du rÃ©sumÃ© de migration..."
  
  # CrÃ©ation du rapport final en JSON
  cat > "${REPORTS_DIR}/migration_summary.json" << EOL
{
  "timestamp": "$(date -u +"%Y-%m-%dT%H:%M:%SZ")",
  "status": "completed",
  "source": {
    "type": "mysql",
    "database": "$(load_config '.mysql.database' "")",
    "tables": [$(echo "$TABLES" | sed 's/ /","/g' | sed 's/^/"/' | sed 's/$/"/')],
    "records": {}
  },
  "target": {
    "type": "supabase",
    "url": "$(load_config '.supabase.url' "" | sed 's/\(https:\/\/\)\([^\.]*\)\..*/\1\2/')",
    "tables": [$(echo "$TABLES" | sed 's/ /","/g' | sed 's/^/"/' | sed 's/$/"/')],
    "records": {}
  },
  "exportFormat": "$EXPORT_FORMAT",
  "navicat": $([ "$SKIP_NAVICAT" = true ] && echo "false" || echo "true"),
  "n8n": $([ "$USE_N8N" = true ] && echo "true" || echo "false"),
  "reportsPath": "$REPORTS_DIR",
  "logsPath": "$LOGS_DIR"
}
EOL
  
  # Si l'intÃ©gration avec n8n est activÃ©e, dÃ©clencher le webhook
  if [ "$USE_N8N" = true ]; then
    # RÃ©cupÃ©rer l'URL du webhook depuis le config
    WEBHOOK_URL=$(load_config '.n8n.webhookUrl' "")
    
    if [ -n "$WEBHOOK_URL" ]; then
      log "INFO" "DÃ©clenchement du webhook n8n..."
      run_command "curl -s -X POST $WEBHOOK_URL \
        -H 'Content-Type: application/json' \
        -d @${REPORTS_DIR}/migration_summary.json" \
        "DÃ©clenchement du webhook" "webhook.log" "continue"
    fi
  fi
  
  log "SUCCESS" "ðŸŽ‰ Migration terminÃ©e avec succÃ¨s! Rapports disponibles dans: $REPORTS_DIR"
  
  # GÃ©nÃ©rer un rapport Markdown plus lisible
  cat > "${REPORTS_DIR}/migration_summary.md" << EOL
# Rapport de migration MySQL â†’ Supabase

**Date:** $(date +"%Y-%m-%d %H:%M:%S")

## RÃ©sumÃ©

- **Source MySQL:** $(load_config '.mysql.database' "")
- **Destination Supabase:** $(load_config '.supabase.url' "" | sed 's/\(https:\/\/\)\([^\.]*\)\..*/\1\2/')
- **Tables migrÃ©es:** $TABLES
- **Format d'export:** $EXPORT_FORMAT
- **Utilisation de Navicat:** $([ "$SKIP_NAVICAT" = true ] && echo "Non" || echo "Oui")
- **Orchestration n8n:** $([ "$USE_N8N" = true ] && echo "Oui" || echo "Non")

## Rapports dÃ©taillÃ©s

- VÃ©rification des donnÃ©es: [migration_report.json](./migration_report.json)
- Mapping des schÃ©mas: [schema_map.json](./schema_map.json)
- Logs complets: $LOGS_DIR/migration.log

## Prochaines Ã©tapes

1. VÃ©rifier l'intÃ©gritÃ© des donnÃ©es dans Supabase
2. Mettre Ã  jour les configurations de l'application pour pointer vers Supabase
3. Effectuer des tests de l'application avec la nouvelle base de donnÃ©es
EOL
  
  echo -e "\nðŸ“‘ RÃ©sumÃ© de la migration: ${REPORTS_DIR}/migration_summary.md"
}

# Fonction principale
main() {
  log "INFO" "ðŸš€ DÃ©marrage de la migration MySQL â†’ Supabase (PostgreSQL)"
  
  check_prerequisites
  extract_and_map
  export_data
  upload_to_supabase
  verify_data
  finalize
}

# ExÃ©cuter la fonction principale
main