#!/bin/bash
set -e

# Couleurs pour une meilleure lisibilitÃ©
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
RED='\033[0;31m'
NC='\033[0m' # No Color

# Fonction pour afficher des messages avec timestamp
log() {
  echo -e "${BLUE}[$(date +'%Y-%m-%d %H:%M:%S')]${NC} $1"
}

# Fonction pour afficher des Ã©tapes
step() {
  echo -e "\n${GREEN}=== Ã‰TAPE $1: $2 ===${NC}\n"
}

# Fonction pour afficher des avertissements
warn() {
  echo -e "${YELLOW}âš ï¸  $1${NC}"
}

# Fonction pour afficher des erreurs
error() {
  echo -e "${RED}âŒ $1${NC}"
  exit 1
}

# VÃ©rification de l'environnement
check_env() {
  step "1" "VÃ©rification de l'environnement"
  
  # VÃ©rifier si le fichier .env existe, sinon le crÃ©er Ã  partir du modÃ¨le
  if [ ! -f .env ]; then
    if [ -f .env.example ]; then
      log "CrÃ©ation du fichier .env Ã  partir de .env.example"
      cp .env.example .env
      warn "Fichier .env crÃ©Ã© Ã  partir du modÃ¨le. Veuillez vÃ©rifier et ajuster les valeurs si nÃ©cessaire."
    else
      error "Aucun fichier .env ou .env.example trouvÃ©. Veuillez en crÃ©er un avec les variables requises."
    fi
  fi
  
  # Charger les variables d'environnement
  log "Chargement des variables d'environnement"
  export $(grep -v '^#' .env | xargs)
  
  # VÃ©rifier les variables essentielles
  if [ -z "$MYSQL_ROOT_PASSWORD" ] || [ -z "$POSTGRES_PASSWORD" ]; then
    error "Variables d'environnement MYSQL_ROOT_PASSWORD ou POSTGRES_PASSWORD non dÃ©finies dans le fichier .env"
  fi
  
  # DÃ©tection de l'architecture
  ARCH=$(uname -m)
  if [ "$ARCH" = "arm64" ] || [ "$ARCH" = "aarch64" ]; then
    log "Architecture ARM dÃ©tectÃ©e: $ARCH"
    export DOCKER_PLATFORM="linux/arm64"
  else
    log "Architecture x86 dÃ©tectÃ©e: $ARCH"
    export DOCKER_PLATFORM="linux/amd64"
  fi
  
  log "Environnement vÃ©rifiÃ© avec succÃ¨s âœ…"
}

# DÃ©marrage des containers Docker
start_containers() {
  step "2" "DÃ©marrage des containers Docker"
  
  # ArrÃªter les containers existants si besoin
  if [ "$1" = "--force" ] || [ "$1" = "-f" ]; then
    log "ArrÃªt des containers existants..."
    docker-compose -f docker-compose.dev.yml down
  fi
  
  # DÃ©marrer les containers
  log "DÃ©marrage des containers Docker..."
  docker-compose -f docker-compose.dev.yml up -d
  
  # Attendre que les bases de donnÃ©es soient prÃªtes
  log "Attente de la disponibilitÃ© de MySQL..."
  until docker-compose -f docker-compose.dev.yml exec -T mysql-legacy mysqladmin ping -h localhost -u root -p"$MYSQL_ROOT_PASSWORD" --silent; do
    echo -n "."
    sleep 2
  done
  
  log "Attente de la disponibilitÃ© de PostgreSQL..."
  until docker-compose -f docker-compose.dev.yml exec -T postgres-intermediate pg_isready -U "$POSTGRES_USER" -d "$POSTGRES_DB"; do
    echo -n "."
    sleep 2
  done
  
  log "Tous les containers sont dÃ©marrÃ©s et opÃ©rationnels âœ…"
}

# Injection des dumps dans les bases de donnÃ©es
inject_dumps() {
  step "3" "Injection des dumps de donnÃ©es"
  
  # VÃ©rifier s'il existe des dumps Ã  injecter
  MYSQL_DUMPS_DIR="./scripts/mysql/dumps"
  POSTGRES_DUMPS_DIR="./scripts/postgres/dumps"
  
  # Injection des dumps MySQL
  if [ -d "$MYSQL_DUMPS_DIR" ] && [ "$(ls -A $MYSQL_DUMPS_DIR)" ]; then
    log "Injection des dumps MySQL..."
    for dump in $MYSQL_DUMPS_DIR/*.sql; do
      if [ -f "$dump" ]; then
        DUMP_NAME=$(basename "$dump")
        log "Injection de $DUMP_NAME dans MySQL..."
        docker-compose -f docker-compose.dev.yml exec -T mysql-legacy mysql -u root -p"$MYSQL_ROOT_PASSWORD" "$MYSQL_DATABASE" < "$dump"
      fi
    done
  else
    warn "Aucun dump MySQL trouvÃ© dans $MYSQL_DUMPS_DIR"
  fi
  
  # Injection des dumps PostgreSQL
  if [ -d "$POSTGRES_DUMPS_DIR" ] && [ "$(ls -A $POSTGRES_DUMPS_DIR)" ]; then
    log "Injection des dumps PostgreSQL..."
    for dump in $POSTGRES_DUMPS_DIR/*.sql; do
      if [ -f "$dump" ]; then
        DUMP_NAME=$(basename "$dump")
        log "Injection de $DUMP_NAME dans PostgreSQL..."
        docker-compose -f docker-compose.dev.yml exec -T postgres-intermediate psql -U "$POSTGRES_USER" -d "$POSTGRES_DB" < "$dump"
      fi
    done
  else
    warn "Aucun dump PostgreSQL trouvÃ© dans $POSTGRES_DUMPS_DIR"
  fi
  
  # Injection des donnÃ©es de seed pour tests si disponibles
  MYSQL_SEED="./scripts/mysql/seed.sql"
  POSTGRES_SEED="./scripts/postgres/seed.sql"
  
  if [ -f "$MYSQL_SEED" ]; then
    log "Injection des donnÃ©es de test MySQL..."
    docker-compose -f docker-compose.dev.yml exec -T mysql-legacy mysql -u root -p"$MYSQL_ROOT_PASSWORD" "$MYSQL_DATABASE" < "$MYSQL_SEED"
  fi
  
  if [ -f "$POSTGRES_SEED" ]; then
    log "Injection des donnÃ©es de test PostgreSQL..."
    docker-compose -f docker-compose.dev.yml exec -T postgres-intermediate psql -U "$POSTGRES_USER" -d "$POSTGRES_DB" < "$POSTGRES_SEED"
  fi
  
  log "Injection des dumps terminÃ©e âœ…"
}

# DÃ©marrage des agents MCP
start_mcp_agents() {
  step "4" "DÃ©marrage des agents MCP"
  
  # Attendre que les serveurs MCP soient prÃªts
  log "Attente de la disponibilitÃ© des serveurs MCP..."
  # VÃ©rifier si MCP MySQL est prÃªt
  MCP_MYSQL_PORT=${MCP_MYSQL_PORT:-3002}
  until curl -s "http://localhost:$MCP_MYSQL_PORT/health" > /dev/null; do
    echo -n "."
    sleep 2
  done
  
  # VÃ©rifier si MCP PostgreSQL est prÃªt
  MCP_POSTGRES_PORT=${MCP_POSTGRES_PORT:-3003}
  until curl -s "http://localhost:$MCP_POSTGRES_PORT/health" > /dev/null; do
    echo -n "."
    sleep 2
  done
  
  log "ExÃ©cution de l'agent MySQL Analyzer..."
  docker-compose -f docker-compose.dev.yml exec -T code-transformer node /app/bin/mysql-analyzer.js

  log "ExÃ©cution de l'agent MySQL-to-PostgreSQL..."
  docker-compose -f docker-compose.dev.yml exec -T code-transformer node /app/bin/mysql-to-pg.js

  log "ExÃ©cution de l'agent Sync-Mapper..."
  docker-compose -f docker-compose.dev.yml exec -T code-transformer node /app/bin/sync-mapper.js
  
  log "Tous les agents MCP sont dÃ©marrÃ©s âœ…"
}

# GÃ©nÃ©ration du schema Prisma
generate_prisma_schema() {
  step "5" "GÃ©nÃ©ration du schema Prisma"
  
  log "ExÃ©cution du gÃ©nÃ©rateur de schema Prisma..."
  docker-compose -f docker-compose.dev.yml run --rm prisma-generator
  
  log "VÃ©rification du schema gÃ©nÃ©rÃ©..."
  if [ -f "./apps/frontend/prisma/schema.prisma" ]; then
    log "Schema Prisma gÃ©nÃ©rÃ© avec succÃ¨s âœ…"
  else
    warn "Le schema Prisma n'a pas Ã©tÃ© gÃ©nÃ©rÃ© correctement. VÃ©rifiez les logs du container prisma-generator."
  fi
}

# Push vers Supabase
push_to_supabase() {
  step "6" "Push vers Supabase"
  
  # VÃ©rifier si les variables Supabase sont dÃ©finies
  if [ -z "$SUPABASE_ACCESS_TOKEN" ] || [ -z "$SUPABASE_PROJECT_ID" ]; then
    warn "Variables Supabase non dÃ©finies. Ã‰tape de push vers Supabase ignorÃ©e."
    return
  fi
  
  if [ "$DRY_RUN" = "true" ]; then
    log "Mode DRY RUN activÃ© - Simulation du push vers Supabase"
    docker-compose -f docker-compose.dev.yml run --rm supabase-cli supabase db diff --use-migra --schema public
  else
    log "Push vers Supabase..."
    docker-compose -f docker-compose.dev.yml run --rm supabase-cli supabase db push
  fi
  
  log "Push vers Supabase terminÃ© âœ…"
}

# Lancement du workflow n8n
trigger_n8n_workflow() {
  step "7" "DÃ©clenchement du workflow n8n"
  
  # Attendre que n8n soit prÃªt
  log "Attente de la disponibilitÃ© de n8n..."
  N8N_PORT=${N8N_PORT:-5678}
  until curl -s "http://localhost:$N8N_PORT/healthz" > /dev/null; do
    echo -n "."
    sleep 2
  done
  
  # Identifier l'ID du workflow Ã  dÃ©clencher
  WORKFLOW_NAME="Migration Data Validator"
  
  if [ "$DRY_RUN" = "true" ]; then
    log "Mode DRY RUN activÃ© - Simulation du dÃ©clenchement du workflow n8n '$WORKFLOW_NAME'"
  else
    log "DÃ©clenchement du workflow n8n '$WORKFLOW_NAME'..."
    # Deux mÃ©thodes possibles : webhook ou exÃ©cution directe
    
    # Option 1: Via webhook si configurÃ©
    if [ ! -z "$N8N_WEBHOOK_URL" ]; then
      curl -X POST "$N8N_WEBHOOK_URL" \
        -H "Content-Type: application/json" \
        -d '{"event":"migration_completed","timestamp":"'$(date -u +"%Y-%m-%dT%H:%M:%SZ")'"}'
    # Option 2: Via API n8n
    else
      # RÃ©cupÃ©rer l'ID du workflow
      WORKFLOW_ID=$(curl -s "http://localhost:$N8N_PORT/api/v1/workflows" | grep -o '"id":"[^"]*","name":"'"$WORKFLOW_NAME"'"' | cut -d'"' -f4)
      if [ ! -z "$WORKFLOW_ID" ]; then
        curl -X POST "http://localhost:$N8N_PORT/api/v1/workflows/$WORKFLOW_ID/activate"
      else
        warn "Workflow '$WORKFLOW_NAME' non trouvÃ© dans n8n"
      fi
    fi
  fi
  
  log "Workflow n8n dÃ©clenchÃ© âœ…"
}

# Affichage du rÃ©sumÃ©
show_summary() {
  step "8" "RÃ©sumÃ© du pipeline"
  
  echo -e "${GREEN}âœ… Pipeline de migration exÃ©cutÃ© avec succÃ¨s${NC}"
  echo -e "ğŸ“Š ${BLUE}Statistiques:${NC}"
  echo -e "   - Containers Docker: En cours d'exÃ©cution"
  echo -e "   - Bases de donnÃ©es: MySQL & PostgreSQL initialisÃ©es"
  echo -e "   - Agents MCP: ExÃ©cutÃ©s"
  echo -e "   - Schema Prisma: GÃ©nÃ©rÃ©"
  
  if [ "$DRY_RUN" = "true" ]; then
    echo -e "   - Mode: ${YELLOW}DRY RUN${NC} (aucune modification dans Supabase)"
  else
    echo -e "   - Mode: ${GREEN}PRODUCTION${NC} (donnÃ©es synchronisÃ©es avec Supabase)"
  fi
  
  echo -e "\n${BLUE}Pour accÃ©der aux interfaces:${NC}"
  echo -e "   - Dashboard de migration: http://localhost:3000"
  echo -e "   - Interface n8n: http://localhost:$N8N_PORT"
  echo -e "   - Adminer (DB): http://localhost:8080"
  
  echo -e "\n${YELLOW}Pour arrÃªter le pipeline:${NC} docker-compose -f docker-compose.dev.yml down"
}

# Fonction principale
main() {
  # BanniÃ¨re
  echo -e "${GREEN}"
  echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
  echo "â•‘         PIPELINE DE MIGRATION PHP â†’ NESTJS/REMIX          â•‘"
  echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
  echo -e "${NC}"
  
  # Traitement des arguments
  DRY_RUN=false
  FORCE_RESTART=false
  
  while [[ "$#" -gt 0 ]]; do
    case $1 in
      --dry-run) DRY_RUN=true; shift ;;
      --force|-f) FORCE_RESTART=true; shift ;;
      -h|--help)
        echo "Usage: $0 [options]"
        echo "Options:"
        echo "  --dry-run       ExÃ©cute le pipeline sans Ã©crire dans Supabase"
        echo "  --force, -f     Force le redÃ©marrage des containers existants"
        echo "  --help, -h      Affiche cette aide"
        exit 0
        ;;
      *) error "Option inconnue: $1" ;;
    esac
  done
  
  if [ "$DRY_RUN" = "true" ]; then
    warn "Mode DRY RUN activÃ© - Aucune donnÃ©e ne sera Ã©crite dans Supabase"
  fi
  
  # ExÃ©cution des Ã©tapes
  check_env
  
  if [ "$FORCE_RESTART" = "true" ]; then
    start_containers --force
  else
    start_containers
  fi
  
  inject_dumps
  start_mcp_agents
  generate_prisma_schema
  push_to_supabase
  trigger_n8n_workflow
  show_summary
}

# ExÃ©cution du script
main "$@"