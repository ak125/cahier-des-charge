#!/bin/bash
set -e

# Couleurs pour une meilleure lisibilit√©
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
RED='\033[0;31m'
NC='\033[0m' # No Color

# Fonction pour afficher des messages avec timestamp
log() {
  echo -e "${BLUE}[$(date +'%Y-%m-%d %H:%M:%S')]${NC} $1"
}

# Fonction pour afficher des √©tapes
step() {
  echo -e "\n${GREEN}=== √âTAPE $1: $2 ===${NC}\n"
}

# Fonction pour afficher des avertissements
warn() {
  echo -e "${YELLOW}‚ö†Ô∏è  $1${NC}"
}

# Fonction pour afficher des erreurs
error() {
  echo -e "${RED}‚ùå $1${NC}"
  exit 1
}

# V√©rification de l'environnement
check_env() {
  step "1" "V√©rification de l'environnement"
  
  # V√©rifier si le fichier .env existe, sinon le cr√©er √† partir du mod√®le
  if [ ! -f .env ]; then
    if [ -f .env.example ]; then
      log "Cr√©ation du fichier .env √† partir de .env.example"
      cp .env.example .env
      warn "Fichier .env cr√©√© √† partir du mod√®le. Veuillez v√©rifier et ajuster les valeurs si n√©cessaire."
    else
      error "Aucun fichier .env ou .env.example trouv√©. Veuillez en cr√©er un avec les variables requises."
    fi
  fi
  
  # Charger les variables d'environnement
  log "Chargement des variables d'environnement"
  export $(grep -v '^#' .env | xargs)
  
  # V√©rifier les variables essentielles
  if [ -z "$MYSQL_ROOT_PASSWORD" ] || [ -z "$POSTGRES_PASSWORD" ]; then
    error "Variables d'environnement MYSQL_ROOT_PASSWORD ou POSTGRES_PASSWORD non d√©finies dans le fichier .env"
  fi
  
  # D√©tection de l'architecture
  ARCH=$(uname -m)
  if [ "$ARCH" = "arm64" ] || [ "$ARCH" = "aarch64" ]; then
    log "Architecture ARM d√©tect√©e: $ARCH"
    export DOCKER_PLATFORM="linux/arm64"
  else
    log "Architecture x86 d√©tect√©e: $ARCH"
    export DOCKER_PLATFORM="linux/amd64"
  fi
  
  log "Environnement v√©rifi√© avec succ√®s ‚úÖ"
}

# D√©marrage des containers Docker
start_containers() {
  step "2" "D√©marrage des containers Docker"
  
  # Arr√™ter les containers existants si besoin
  if [ "$1" = "--force" ] || [ "$1" = "-f" ]; then
    log "Arr√™t des containers existants..."
    docker-compose -f docker-compose.dev.yml down
  fi
  
  # D√©marrer les containers
  log "D√©marrage des containers Docker..."
  docker-compose -f docker-compose.dev.yml up -d
  
  # Attendre que les bases de donn√©es soient pr√™tes
  log "Attente de la disponibilit√© de MySQL..."
  until docker-compose -f docker-compose.dev.yml exec -T mysql-legacy mysqladmin ping -h localhost -u root -p"$MYSQL_ROOT_PASSWORD" --silent; do
    echo -n "."
    sleep 2
  done
  
  log "Attente de la disponibilit√© de PostgreSQL..."
  until docker-compose -f docker-compose.dev.yml exec -T postgres-intermediate pg_isready -U "$POSTGRES_USER" -d "$POSTGRES_DB"; do
    echo -n "."
    sleep 2
  done
  
  log "Tous les containers sont d√©marr√©s et op√©rationnels ‚úÖ"
}

# Injection des dumps dans les bases de donn√©es
inject_dumps() {
  step "3" "Injection des dumps de donn√©es"
  
  # V√©rifier s'il existe des dumps √† injecter
  MYSQL_DUMPS_DIR="./scripts/mysql/dumps"
  POSTGRES_DUMPS_DIR="./scripts/postgres/dumps"
  
  # Injection des dumps MySQL
  if [ -d "$MYSQL_DUMPS_DIR" ] && [ "$(ls -A $MYSQL_DUMPS_DIR)" ]; then
    log "Injection des dumps MySQL..."
    for dump in $MYSQL_DUMPS_DIR/*.sql; do
      if [ -f "$dump" ]; then
        DUMP_NAME=$(basename "$dump")
        log "Injection de $DUMP_NAME dans MySQL..."
        docker-compose -f docker-compose.dev.yml exec -T mysql-legacy mysql -u root -p"$MYSQL_ROOT_PASSWORD" "$MYSQL_DATABASE" < "$dump"
      fi
    done
  else
    warn "Aucun dump MySQL trouv√© dans $MYSQL_DUMPS_DIR"
  fi
  
  # Injection des dumps PostgreSQL
  if [ -d "$POSTGRES_DUMPS_DIR" ] && [ "$(ls -A $POSTGRES_DUMPS_DIR)" ]; then
    log "Injection des dumps PostgreSQL..."
    for dump in $POSTGRES_DUMPS_DIR/*.sql; do
      if [ -f "$dump" ]; then
        DUMP_NAME=$(basename "$dump")
        log "Injection de $DUMP_NAME dans PostgreSQL..."
        docker-compose -f docker-compose.dev.yml exec -T postgres-intermediate psql -U "$POSTGRES_USER" -d "$POSTGRES_DB" < "$dump"
      fi
    done
  else
    warn "Aucun dump PostgreSQL trouv√© dans $POSTGRES_DUMPS_DIR"
  fi
  
  # Injection des donn√©es de seed pour tests si disponibles
  MYSQL_SEED="./scripts/mysql/seed.sql"
  POSTGRES_SEED="./scripts/postgres/seed.sql"
  
  if [ -f "$MYSQL_SEED" ]; then
    log "Injection des donn√©es de test MySQL..."
    docker-compose -f docker-compose.dev.yml exec -T mysql-legacy mysql -u root -p"$MYSQL_ROOT_PASSWORD" "$MYSQL_DATABASE" < "$MYSQL_SEED"
  fi
  
  if [ -f "$POSTGRES_SEED" ]; then
    log "Injection des donn√©es de test PostgreSQL..."
    docker-compose -f docker-compose.dev.yml exec -T postgres-intermediate psql -U "$POSTGRES_USER" -d "$POSTGRES_DB" < "$POSTGRES_SEED"
  fi
  
  log "Injection des dumps termin√©e ‚úÖ"
}

# D√©marrage des agents MCP
start_mcp_agents() {
  step "4" "D√©marrage des agents MCP"
  
  # Attendre que les serveurs MCP soient pr√™ts
  log "Attente de la disponibilit√© des serveurs MCP..."
  # V√©rifier si MCP MySQL est pr√™t
  MCP_MYSQL_PORT=${MCP_MYSQL_PORT:-3002}
  until curl -s "http://localhost:$MCP_MYSQL_PORT/health" > /dev/null; do
    echo -n "."
    sleep 2
  done
  
  # V√©rifier si MCP PostgreSQL est pr√™t
  MCP_POSTGRES_PORT=${MCP_POSTGRES_PORT:-3003}
  until curl -s "http://localhost:$MCP_POSTGRES_PORT/health" > /dev/null; do
    echo -n "."
    sleep 2
  done
  
  log "Ex√©cution de l'agent MySQL Analyzer..."
  docker-compose -f docker-compose.dev.yml exec -T code-transformer node /app/bin/mysql-analyzer.js

  log "Ex√©cution de l'agent MySQL-to-PostgreSQL..."
  docker-compose -f docker-compose.dev.yml exec -T code-transformer node /app/bin/mysql-to-pg.js

  log "Ex√©cution de l'agent Sync-Mapper..."
  docker-compose -f docker-compose.dev.yml exec -T code-transformer node /app/bin/sync-mapper.js
  
  log "Tous les agents MCP sont d√©marr√©s ‚úÖ"
}

# G√©n√©ration du schema Prisma
generate_prisma_schema() {
  step "5" "G√©n√©ration du schema Prisma"
  
  log "Ex√©cution du g√©n√©rateur de schema Prisma..."
  docker-compose -f docker-compose.dev.yml run --rm prisma-generator
  
  log "V√©rification du schema g√©n√©r√©..."
  if [ -f "./apps/frontend/prisma/schema.prisma" ]; then
    log "Schema Prisma g√©n√©r√© avec succ√®s ‚úÖ"
  else
    warn "Le schema Prisma n'a pas √©t√© g√©n√©r√© correctement. V√©rifiez les logs du container prisma-generator."
  fi
}

# Push vers Supabase
push_to_supabase() {
  step "6" "Push vers Supabase"
  
  # V√©rifier si les variables Supabase sont d√©finies
  if [ -z "$SUPABASE_ACCESS_TOKEN" ] || [ -z "$SUPABASE_PROJECT_ID" ]; then
    warn "Variables Supabase non d√©finies. √âtape de push vers Supabase ignor√©e."
    return
  fi
  
  if [ "$DRY_RUN" = "true" ]; then
    log "Mode DRY RUN activ√© - Simulation du push vers Supabase"
    docker-compose -f docker-compose.dev.yml run --rm supabase-cli supabase db diff --use-migra --schema public
  else
    log "Push vers Supabase..."
    docker-compose -f docker-compose.dev.yml run --rm supabase-cli supabase db push
  fi
  
  log "Push vers Supabase termin√© ‚úÖ"
}

# Lancement du workflow n8n
trigger_n8n_workflow() {
  step "7" "D√©clenchement du workflow n8n"
  
  # Attendre que n8n soit pr√™t
  log "Attente de la disponibilit√© de n8n..."
  N8N_PORT=${N8N_PORT:-5678}
  until curl -s "http://localhost:$N8N_PORT/healthz" > /dev/null; do
    echo -n "."
    sleep 2
  done
  
  # Identifier l'ID du workflow √† d√©clencher
  WORKFLOW_NAME="Migration Data Validator"
  
  if [ "$DRY_RUN" = "true" ]; then
    log "Mode DRY RUN activ√© - Simulation du d√©clenchement du workflow n8n '$WORKFLOW_NAME'"
  else
    log "D√©clenchement du workflow n8n '$WORKFLOW_NAME'..."
    # Deux m√©thodes possibles : webhook ou ex√©cution directe
    
    # Option 1: Via webhook si configur√©
    if [ ! -z "$N8N_WEBHOOK_URL" ]; then
      curl -X POST "$N8N_WEBHOOK_URL" \
        -H "Content-Type: application/json" \
        -d '{"event":"migration_completed","timestamp":"'$(date -u +"%Y-%m-%dT%H:%M:%SZ")'"}'
    # Option 2: Via API n8n
    else
      # R√©cup√©rer l'ID du workflow
      WORKFLOW_ID=$(curl -s "http://localhost:$N8N_PORT/api/v1/workflows" | grep -o '"id":"[^"]*","name":"'"$WORKFLOW_NAME"'"' | cut -d'"' -f4)
      if [ ! -z "$WORKFLOW_ID" ]; then
        curl -X POST "http://localhost:$N8N_PORT/api/v1/workflows/$WORKFLOW_ID/activate"
      else
        warn "Workflow '$WORKFLOW_NAME' non trouv√© dans n8n"
      fi
    fi
  fi
  
  log "Workflow n8n d√©clench√© ‚úÖ"
}

# Affichage du r√©sum√©
show_summary() {
  step "8" "R√©sum√© du pipeline"
  
  echo -e "${GREEN}‚úÖ Pipeline de migration ex√©cut√© avec succ√®s${NC}"
  echo -e "üìä ${BLUE}Statistiques:${NC}"
  echo -e "   - Containers Docker: En cours d'ex√©cution"
  echo -e "   - Bases de donn√©es: MySQL & PostgreSQL initialis√©es"
  echo -e "   - Agents MCP: Ex√©cut√©s"
  echo -e "   - Schema Prisma: G√©n√©r√©"
  
  if [ "$DRY_RUN" = "true" ]; then
    echo -e "   - Mode: ${YELLOW}DRY RUN${NC} (aucune modification dans Supabase)"
  else
    echo -e "   - Mode: ${GREEN}PRODUCTION${NC} (donn√©es synchronis√©es avec Supabase)"
  fi
  
  echo -e "\n${BLUE}Pour acc√©der aux interfaces:${NC}"
  echo -e "   - Dashboard de migration: http://localhost:3000"
  echo -e "   - Interface n8n: http://localhost:$N8N_PORT"
  echo -e "   - Adminer (DB): http://localhost:8080"
  
  echo -e "\n${YELLOW}Pour arr√™ter le pipeline:${NC} docker-compose -f docker-compose.dev.yml down"
}

# Fonction principale
main() {
  # Banni√®re
  echo -e "${GREEN}"
  echo "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó"
  echo "‚ïë         PIPELINE DE MIGRATION PHP ‚Üí NESTJS/REMIX          ‚ïë"
  echo "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù"
  echo -e "${NC}"
  
  # Traitement des arguments
  DRY_RUN=false
  FORCE_RESTART=false
  
  while [[ "$#" -gt 0 ]]; do
    case $1 in
      --dry-run) DRY_RUN=true; shift ;;
      --force|-f) FORCE_RESTART=true; shift ;;
      -h|--help)
        echo "Usage: $0 [options]"
        echo "Options:"
        echo "  --dry-run       Ex√©cute le pipeline sans √©crire dans Supabase"
        echo "  --force, -f     Force le red√©marrage des containers existants"
        echo "  --help, -h      Affiche cette aide"
        exit 0
        ;;
      *) error "Option inconnue: $1" ;;
    esac
  done
  
  if [ "$DRY_RUN" = "true" ]; then
    warn "Mode DRY RUN activ√© - Aucune donn√©e ne sera √©crite dans Supabase"
  fi
  
  # Ex√©cution des √©tapes
  check_env
  
  if [ "$FORCE_RESTART" = "true" ]; then
    start_containers --force
  else
    start_containers
  fi
  
  inject_dumps
  start_mcp_agents
  generate_prisma_schema
  push_to_supabase
  trigger_n8n_workflow
  show_summary
}

# Ex√©cution du script
main "$@"